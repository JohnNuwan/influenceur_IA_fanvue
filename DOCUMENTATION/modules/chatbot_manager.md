# ü§ñ Module de Gestion des Chatbots

## üìã Vue d'ensemble

Ce module g√®re les chatbots automatiques pour interagir avec les abonn√©s sur les plateformes de contenu (Fanvue, OnlyFans, Telegram, Discord) et automatiser les ventes de packs.

**Approche Open Source :** Ce module utilise **Ollama** comme LLM local pour les r√©ponses intelligentes, offrant un contr√¥le total et une r√©duction des co√ªts.

---

## üéØ Fonctionnalit√©s principales

### 1. R√©ponses automatiques avec Ollama
- **Messages d'accueil** : Accueil automatique des nouveaux abonn√©s
- **R√©ponses contextuelles** : R√©ponses intelligentes avec LLM local
- **Vente automatique** : Proposition de packs selon les demandes
- **Support client** : R√©ponses aux questions fr√©quentes

### 2. Gestion des conversations
- **Suivi des conversations** : Historique complet des √©changes
- **Classification des messages** : Cat√©gorisation automatique
- **Escalade** : Transfert vers support humain si n√©cessaire
- **Personnalisation** : Adaptation selon le profil utilisateur

### 3. Int√©gration plateformes
- **Fanvue** : Int√©gration API officielle
- **OnlyFans** : Int√©gration via API ou web scraping
- **Telegram** : Bot Telegram personnalis√©
- **Discord** : Bot Discord pour serveurs priv√©s

---

## üèóÔ∏è Architecture technique

### Architecture Ollama
```mermaid
graph TB
    subgraph "Platforms"
        A[Fanvue API]
        B[OnlyFans API]
        C[Telegram Bot]
        D[Discord Bot]
    end
    
    subgraph "Chatbot Manager"
        E[Message Receiver]
        F[Intent Classifier]
        G[Context Manager]
        H[Response Generator]
        I[Action Executor]
    end
    
    subgraph "Ollama LLM"
        J[Ollama Service<br/>llama2:7b]
        K[Ollama Service<br/>mistral:7b]
        L[Prompt Manager]
        M[Response Validator]
    end
    
    subgraph "Storage"
        N[Conversation DB]
        O[User Profiles]
        P[Vector DB<br/>Chroma]
    end
    
    A --> E
    B --> E
    C --> E
    D --> E
    
    E --> F
    F --> G
    G --> H
    H --> I
    
    H --> J
    H --> K
    H --> L
    L --> M
    
    G --> N
    G --> O
    G --> P
    
    I --> A
    I --> B
    I --> C
    I --> D
```

### Flux de conversation avec Ollama
```mermaid
sequenceDiagram
    participant U as User
    participant P as Platform
    participant CM as Chatbot Manager
    participant O as Ollama
    participant DB as Database
    
    U->>P: Envoie message
    P->>CM: Webhook/API call
    CM->>CM: Analyse du message
    CM->>DB: R√©cup√®re contexte utilisateur
    CM->>O: G√©n√®re r√©ponse avec prompt
    O->>CM: Retourne r√©ponse
    CM->>CM: Post-processing
    CM->>DB: Sauvegarde conversation
    CM->>P: Envoie r√©ponse
    P->>U: Affiche r√©ponse
```

### Structure des donn√©es
```json
{
  "conversation_id": "uuid",
  "user_id": "user_123",
  "platform": "fanvue",
  "status": "active",
  "messages": [
    {
      "message_id": "msg_001",
      "timestamp": "2024-01-15T10:30:00Z",
      "sender": "user",
      "content": "Salut, tu as des photos de pieds ?",
      "type": "text",
      "intent": "feet_request"
    },
    {
      "message_id": "msg_002",
      "timestamp": "2024-01-15T10:30:30Z",
      "sender": "bot",
      "content": "Salut beaut√© üòò Oui j'ai un pack pieds exclusif !",
      "type": "text",
      "intent": "feet_response",
      "generated_by": "ollama"
    }
  ],
  "user_profile": {
    "subscription_level": "premium",
    "purchase_history": ["pack_001", "pack_002"],
    "preferences": ["feet", "lingerie"],
    "last_activity": "2024-01-15T10:30:00Z"
  },
  "bot_state": {
    "current_intent": "feet_sales",
    "context": {
      "offered_pack": "feet_pack_001",
      "price": 10.00
    },
    "ollama_model": "llama2:7b",
    "conversation_history": "string"
  }
}
```

### Flux de conversation avec Ollama
```
1. R√©ception du message
   ‚îú‚îÄ‚îÄ Analyse du contenu
   ‚îú‚îÄ‚îÄ Classification de l'intention
   ‚îî‚îÄ‚îÄ Mise √† jour du contexte

2. G√©n√©ration de la r√©ponse (Ollama)
   ‚îú‚îÄ‚îÄ Pr√©paration du prompt
   ‚îú‚îÄ‚îÄ Appel √† Ollama API
   ‚îú‚îÄ‚îÄ Post-processing de la r√©ponse
   ‚îî‚îÄ‚îÄ V√©rification des r√®gles

3. Envoi de la r√©ponse
   ‚îú‚îÄ‚îÄ Formatage du message
   ‚îú‚îÄ‚îÄ Envoi via API
   ‚îî‚îÄ‚îÄ Log de l'action

4. Suivi post-r√©ponse
   ‚îú‚îÄ‚îÄ Mise √† jour des m√©triques
   ‚îú‚îÄ‚îÄ Gestion des actions
   ‚îî‚îÄ‚îÄ Planification des follow-ups
```

---

## üîß Configuration Ollama

### Installation et Configuration
```yaml
# docker-compose.yml
services:
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    command: >
      sh -c "
        ollama pull llama2:7b &&
        ollama pull mistral:7b &&
        ollama serve
      "
```

### Mod√®les Ollama recommand√©s
```yaml
models:
  primary:
    name: "llama2:7b"
    description: "Mod√®le principal pour les r√©ponses g√©n√©rales"
    parameters:
      temperature: 0.7
      top_p: 0.9
      max_tokens: 500
  
  sales:
    name: "mistral:7b"
    description: "Mod√®le sp√©cialis√© pour les ventes"
    parameters:
      temperature: 0.8
      top_p: 0.95
      max_tokens: 300
  
  support:
    name: "llama2:7b"
    description: "Mod√®le pour le support client"
    parameters:
      temperature: 0.5
      top_p: 0.8
      max_tokens: 400
```

### Configuration des prompts
```yaml
prompts:
  system_prompt: |
    Tu es une influenceuse NSFW fran√ßaise qui g√®re des conversations avec ses abonn√©s.
    Tu dois √™tre chaleureuse, s√©ductrice mais professionnelle.
    Tu vends des packs de photos (lingerie, pieds, nude artistique).
    R√©ponds toujours en fran√ßais avec des emojis appropri√©s.
    Ne sois jamais vulgaire ou explicite, reste dans le cadre du glamour.

  context_template: |
    Contexte utilisateur:
    - Niveau d'abonnement: {subscription_level}
    - Historique d'achat: {purchase_history}
    - Pr√©f√©rences: {preferences}
    - Derni√®re activit√©: {last_activity}
    
    Conversation r√©cente:
    {conversation_history}
    
    Message actuel: {current_message}
    
    G√©n√®re une r√©ponse appropri√©e et engageante.

  sales_prompt: |
    L'utilisateur semble int√©ress√© par {pack_type}.
    Propose-lui le pack {pack_id} au prix de {price}‚Ç¨.
    Sois persuasive mais pas insistante.
    Inclus des d√©tails sur le contenu du pack.
```

---

## üîß Configuration des plateformes

### Fanvue API
```yaml
api_key: "your_fanvue_api_key"
api_secret: "your_fanvue_api_secret"
webhook_url: "https://your-domain.com/webhook/fanvue"

features:
  - auto_response
  - message_history
  - user_management
  - sales_tracking

limits:
  messages_per_minute: 10
  daily_messages: 1000
```

### OnlyFans API
```yaml
api_key: "your_onlyfans_api_key"
api_secret: "your_onlyfans_api_secret"
webhook_url: "https://your-domain.com/webhook/onlyfans"

features:
  - auto_response
  - content_management
  - subscription_management
  - analytics

limits:
  messages_per_minute: 5
  daily_messages: 500
```

### Telegram Bot
```yaml
bot_token: "your_telegram_bot_token"
webhook_url: "https://your-domain.com/webhook/telegram"

commands:
  - /start: "Accueil et pr√©sentation"
  - /packs: "Liste des packs disponibles"
  - /pricing: "Tarifs et promotions"
  - /help: "Aide et support"

features:
  - inline_keyboards
  - media_support
  - group_chat_support
```

### Discord Bot
```yaml
bot_token: "your_discord_bot_token"
guild_id: "your_guild_id"
webhook_url: "https://your-domain.com/webhook/discord"

channels:
  - name: "general"
    permissions: ["read", "send_messages"]
  - name: "nsfw"
    permissions: ["read", "send_messages", "attach_files"]

features:
  - slash_commands
  - role_management
  - moderation_tools
```

---

## üìù Templates de r√©ponses avec Ollama

### Messages d'accueil
```yaml
templates:
  welcome_new_subscriber:
    fanvue:
      prompt: |
        L'utilisateur vient de s'abonner. Accueille-le chaleureusement et propose-lui de d√©couvrir tes packs.
        Sois s√©ductrice mais pas vulgaire.
      ollama_model: "llama2:7b"
      delay: 30
      follow_up: "pieds_offer"
    
    onlyfans:
      prompt: |
        Nouvel abonn√© sur OnlyFans. Accueille-le et pr√©sente tes services.
        Mentionne tes packs exclusifs.
      ollama_model: "llama2:7b"
      delay: 45
      follow_up: "lingerie_offer"
```

### R√©ponses aux demandes
```yaml
templates:
  feet_request:
    prompt: |
      L'utilisateur demande des photos de pieds.
      Propose-lui le pack pieds exclusif √† 10‚Ç¨.
      Sois s√©ductrice et persuasive.
    ollama_model: "mistral:7b"
    actions:
      - type: "offer_pack"
        pack_id: "feet_pack_001"
        price: 10.00
      - type: "schedule_follow_up"
        delay: 3600
        message: "Tu as pens√© √† mon pack pieds ? üòè Il est toujours disponible !"
    
  lingerie_request:
    prompt: |
      L'utilisateur s'int√©resse aux photos lingerie.
      Propose le pack lingerie √† 15‚Ç¨.
      D√©cris le contenu de mani√®re attrayante.
    ollama_model: "mistral:7b"
    actions:
      - type: "offer_pack"
        pack_id: "lingerie_pack_001"
        price: 15.00
      - type: "schedule_follow_up"
        delay: 7200
        message: "Mon pack lingerie t'attend toujours... üî•"
    
  nude_request:
    prompt: |
      L'utilisateur demande des photos nues.
      Propose le pack nude artistique √† 25‚Ç¨.
      Reste dans le cadre du glamour.
    ollama_model: "mistral:7b"
    actions:
      - type: "offer_pack"
        pack_id: "nude_pack_001"
        price: 25.00
      - type: "schedule_follow_up"
        delay: 10800
        message: "Mon pack nude est toujours l√† si tu veux... üíã"
```

### R√©ponses de support
```yaml
templates:
  pricing_question:
    prompt: |
      L'utilisateur demande les tarifs.
      Liste tous tes packs avec leurs prix.
      Sois claire et professionnelle.
    ollama_model: "llama2:7b"
    
  technical_issue:
    prompt: |
      L'utilisateur a un probl√®me technique.
      Sois empathique et propose de l'aider.
      Demande plus de d√©tails.
    ollama_model: "llama2:7b"
    escalation: true
    
  spam_detection:
    prompt: |
      L'utilisateur envoie trop de messages.
      Sois polie mais ferme.
      Demande-lui d'√™tre plus sp√©cifique.
    ollama_model: "llama2:7b"
    cooldown: 300
```

---

## üîÑ Workflow automatis√© avec Ollama

### Processus de r√©ponse
```mermaid
flowchart TD
    A[Message re√ßu] --> B{Analyse du contenu}
    B --> C[Classification intention]
    C --> D[R√©cup√©ration contexte]
    D --> E[Pr√©paration prompt]
    E --> F[Appel Ollama API]
    F --> G{Validation r√©ponse}
    G -->|OK| H[Post-processing]
    G -->|KO| I[G√©n√©ration fallback]
    H --> J[Envoi r√©ponse]
    I --> J
    J --> K[Sauvegarde conversation]
    K --> L[Mise √† jour m√©triques]
```

### Gestion des ventes avec IA
```
1. D√©tection de l'int√©r√™t
   ‚îú‚îÄ‚îÄ Analyse des mots-cl√©s
   ‚îú‚îÄ‚îÄ Historique d'achat
   ‚îî‚îÄ‚îÄ Comportement utilisateur

2. Proposition de pack (Ollama)
   ‚îú‚îÄ‚îÄ G√©n√©ration de proposition personnalis√©e
   ‚îú‚îÄ‚îÄ S√©lection du pack appropri√©
   ‚îî‚îÄ‚îÄ Envoi du lien d'achat

3. Suivi de la vente
   ‚îú‚îÄ‚îÄ Confirmation d'achat
   ‚îú‚îÄ‚îÄ Envoi du contenu
   ‚îî‚îÄ‚îÄ Demande de feedback

4. Follow-up intelligent
   ‚îú‚îÄ‚îÄ Remerciement personnalis√©
   ‚îú‚îÄ‚îÄ Proposition d'autres packs
   ‚îî‚îÄ‚îÄ Demande de recommandation
```

---

## üìä M√©triques et KPIs

### M√©triques de performance
- **Taux de r√©ponse** : Pourcentage de messages r√©pondus
- **Temps de r√©ponse** : Temps moyen de r√©ponse (objectif < 20s)
- **Taux de conversion** : Pourcentage de ventes r√©ussies
- **Satisfaction client** : Score de satisfaction
- **Performance Ollama** : Temps de g√©n√©ration, qualit√© des r√©ponses

### Alertes automatiques
- **Temps de r√©ponse √©lev√©** : Plus de 30 secondes
- **Taux de conversion faible** : Moins de 5%
- **Spam d√©tect√©** : Trop de messages d'un utilisateur
- **Erreur Ollama** : Probl√®me avec le LLM local
- **Erreur technique** : Probl√®me avec l'API

---

## üõ†Ô∏è Int√©gration avec d'autres modules

### Module de gestion des ventes
- **Proposition de packs** : Int√©gration avec le catalogue
- **Suivi des transactions** : Confirmation des achats
- **Gestion des promotions** : Codes promo automatiques

### Module d'analytics
- **M√©triques de conversation** : Envoi des statistiques
- **Analyse des comportements** : Patterns d'utilisation
- **Optimisation** : Suggestions d'am√©lioration

### Module de g√©n√©ration de contenu
- **Demande de contenu** : G√©n√©ration selon les demandes
- **Personnalisation** : Contenu adapt√© aux pr√©f√©rences
- **Feedback** : Am√©lioration bas√©e sur les retours

---

## üîê S√©curit√© et conformit√©

### S√©curit√©
- **Chiffrement** : Chiffrement des conversations
- **Authentification** : V√©rification des utilisateurs
- **Audit** : Logs de toutes les interactions
- **Rate limiting** : Limitation des messages
- **Validation Ollama** : Filtrage des r√©ponses inappropri√©es

### Conformit√©
- **RGPD** : Gestion des donn√©es personnelles
- **Age verification** : V√©rification de l'√¢ge
- **Content guidelines** : Respect des guidelines
- **Data retention** : Politique de conservation

---

## üöÄ Plan d'impl√©mentation

### Phase 1 : MVP avec Ollama (3 semaines)
1. **Semaine 1** : Setup Ollama et int√©gration de base
2. **Semaine 2** : Templates de base et r√©ponses automatiques
3. **Semaine 3** : Gestion des ventes et follow-ups

### Phase 2 : Extension (2 semaines)
1. **Semaine 4** : Int√©gration OnlyFans et Telegram
2. **Semaine 5** : Analytics et optimisation

### Phase 3 : Optimisation (1 semaine)
1. **Semaine 6** : A/B testing et am√©lioration des performances

---

## üìù Exemples d'utilisation

### Configuration du chatbot avec Ollama
```python
# Exemple d'utilisation du module
from chatbot_manager import ChatbotManager

manager = ChatbotManager()

# Configuration pour Ollama
ollama_config = {
    "url": "http://ollama:11434",
    "model": "llama2:7b",
    "temperature": 0.7,
    "max_tokens": 500
}

# Configuration pour Fanvue
fanvue_config = {
    "api_key": "your_api_key",
    "auto_response": True,
    "sales_enabled": True,
    "ollama_config": ollama_config
}

manager.configure_platform("fanvue", fanvue_config)
```

### Gestion d'une conversation avec Ollama
```python
# Gestion automatique d'une conversation
conversation = manager.handle_message(
    platform="fanvue",
    user_id="user_123",
    message="Salut, tu as des photos de pieds ?",
    context={
        "subscription_level": "premium",
        "purchase_history": ["pack_001"],
        "ollama_model": "mistral:7b"
    }
)

# R√©ponse automatique g√©n√©r√©e par Ollama
response = conversation.get_response()
# "Salut beaut√© üòò Oui j'ai un pack pieds exclusif avec 10 photos hyper sexy pour seulement 10‚Ç¨ !"
```

---

## üîß Configuration Docker

### Dockerfile pour le module chatbot
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Installation des d√©pendances
COPY requirements.txt .
RUN pip install -r requirements.txt

# Installation d'Ollama (si n√©cessaire)
RUN curl -fsSL https://ollama.ai/install.sh | sh

# Copie du code
COPY . .

# Exposition du port
EXPOSE 8000

# Commande de d√©marrage
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Requirements pour Ollama
```txt
fastapi==0.104.1
uvicorn==0.24.0
requests==2.31.0
pydantic==2.5.0
python-dotenv==1.0.0
redis==5.0.1
psycopg2-binary==2.9.9
langchain==0.1.0
langchain-community==0.0.10
chromadb==0.4.18
sentence-transformers==2.2.2
```

---

*Document cr√©√© le : [Date]*
*Version : 2.0*
*Derni√®re mise √† jour : [Date]*
*Approche : Open Source avec Ollama pour LLM local*
